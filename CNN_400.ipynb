{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fbc309f-cc21-4eab-b90b-9a316a4a7a46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Loading in libraries necessary for CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD, Adagrad, RMSprop, SparseAdam, LBFGS, Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import nmrsim\n",
    "from nmrsim import plt\n",
    "from itertools import product\n",
    "\n",
    "# whether to run on GPU or CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device} device\")\n",
    "#print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c766a858-8740-45da-8d9d-2776f23633d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files:  100\n"
     ]
    }
   ],
   "source": [
    "#Checking how many files are in repository for training, testing, and validation\n",
    "files = glob.glob('/home/fostooq/NMR_Upscale_UW_DIRECT/Spectral_Data/Jupyter_NB/spectral_data/400MHz/spectral_data_*.csv')\n",
    "print('Total number of files: ', len(files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13bcae0-0c7f-451e-9cf8-1158cd036411",
   "metadata": {},
   "source": [
    "Establishing a Dataloader for 400MHz dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1db4476-3487-45a3-966f-82dc26c48883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GHzData(Dataset):\n",
    "    def __init__(self):\n",
    "        # Data loading starting with list of csv strings\n",
    "        self.files = glob.glob(os.path.join('/home/fostooq/NMR_Upscale_UW_DIRECT/Spectral_Data/Jupyter_NB/spectral_data/400MHz/spectral_data_*.csv'))\n",
    "\n",
    "        self.y_60 = [] # Establishes a list for 60 MHz data\n",
    "        self.y_400 = [] # Establishes a list for 400 MHz data\n",
    "\n",
    "        for self.file in self.files: # For loop for each file in files\n",
    "            self.df = pd.read_csv(self.file) # Reads each into a pandas dataframe\n",
    "            self.array_60 = self.df['60MHz_intensity'].to_numpy() # Takes 60MHz intensity to np\n",
    "            self.array_400 = self.df['400MHz_intensity'].to_numpy() # Takes 400MHz intensity to np\n",
    "            self.y_60.append(self.array_60) # Appends all arrays to 60MHz list\n",
    "            self.y_400.append(self.array_400) # Appends all arrays to 400MHz list\n",
    "            \n",
    "        # Creates a 60 MHz tensor from list, converts to float, unsqueezes to have shape (n, 1, 5500)\n",
    "        self.tensor_60 = torch.Tensor(self.y_60).float().unsqueeze(1).to(device)        \n",
    "\n",
    "        # Creates a 400 MHz tensor from list, converts to float, unsqueezes to have shape (n, 1, 5500)\n",
    "        self.tensor_400 = torch.Tensor(self.y_400).float().unsqueeze(1).to(device)\n",
    "        \n",
    "        # Track the length of number of samples in frame\n",
    "        self.num_samples = len(self.y_60)\n",
    "\n",
    "    def __getitem__(self, index): # establishes an index for the tensors\n",
    "        return self.tensor_60[index], self.tensor_400[index]\n",
    "    \n",
    "    def __len__(self): # Returns variable number of samples\n",
    "        return self.num_samples\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d27cd0c-1a07-4f1b-b957-b4bcec7c17a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Conv1d(in_channels= 1,out_channels= 128, kernel_size= 3, padding='same') # input layer to hidden\n",
    "        self.relu = nn.ReLU() # activation function\n",
    "        self.fc2 = nn.Conv1d(in_channels=128,out_channels=128,kernel_size= 3, padding='same') # input layer to output\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Conv1d(in_channels=128,out_channels=128,kernel_size= 3, padding='same')\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Conv1d(in_channels=128, out_channels=128,kernel_size= 3, padding='same')\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc5 = nn.Conv1d(in_channels=128,out_channels= 1,kernel_size= 3, padding='same')\n",
    "            \n",
    "    def forward(self, x):  # Forward loop for the neural network\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25ba8f93-ba38-4c86-a0c9-5a3bf1ab46ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device) # Assigns model to variable model, sends to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b074adcf-0cd6-44d5-b922-dfd32bba832e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Establishing and loading data into notebook\n",
    "dataset = GHzData()\n",
    "\n",
    "#Splitting the data\n",
    "train_X, test_X, train_y, test_y = train_test_split(dataset.tensor_60, dataset.tensor_400,\n",
    "                                                    test_size=0.1)\n",
    "\n",
    "# Splits train data into validation data\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y,\n",
    "                                                      test_size=0.1)\n",
    "# Creating datasets\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "test_dataset = TensorDataset(test_X, test_y)\n",
    "valid_dataset = TensorDataset(valid_X, valid_y)\n",
    "\n",
    "# Batch size change to higher batch sizes\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d12cf037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5500])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ab267e0-afa6-498a-ac2c-8a6afebcfa5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # Loss function for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "767eae75-b1ed-4f08-9c57-f4c34b7ea141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#RMSprop and Adam seems to work ptetty well\n",
    "optimizer = RMSprop(model.parameters(), lr=0.001) # Optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c7e95e4-fc5d-4a2c-939f-a00869141f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30 # Number of epochs to run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ce1c1-e120-4675-a0f2-24db74a56a58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.7062e-04, 2.7196e-04, 2.7331e-04,  ..., 7.8373e-05,\n",
      "          7.8226e-05, 7.8079e-05]],\n",
      "\n",
      "        [[6.8608e-04, 6.8868e-04, 6.9131e-04,  ..., 1.6402e-04,\n",
      "          1.6377e-04, 1.6352e-04]],\n",
      "\n",
      "        [[4.8071e-04, 4.8292e-04, 4.8516e-04,  ..., 2.8591e-05,\n",
      "          2.8561e-05, 2.8530e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.2878e-04, 3.3022e-04, 3.3166e-04,  ..., 1.4956e-04,\n",
      "          1.4938e-04, 1.4921e-04]],\n",
      "\n",
      "        [[1.8046e-04, 1.8162e-04, 1.8279e-04,  ..., 4.5711e-05,\n",
      "          4.5665e-05, 4.5619e-05]],\n",
      "\n",
      "        [[2.0318e-04, 2.0437e-04, 2.0557e-04,  ..., 8.1842e-05,\n",
      "          8.1755e-05, 8.1669e-05]]]) tensor([[[-0.0239, -0.0352, -0.0344,  ..., -0.0368, -0.0370, -0.0298]],\n",
      "\n",
      "        [[-0.0239, -0.0352, -0.0344,  ..., -0.0368, -0.0370, -0.0298]],\n",
      "\n",
      "        [[-0.0239, -0.0352, -0.0344,  ..., -0.0368, -0.0370, -0.0298]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0239, -0.0352, -0.0344,  ..., -0.0368, -0.0370, -0.0298]],\n",
      "\n",
      "        [[-0.0239, -0.0352, -0.0344,  ..., -0.0368, -0.0370, -0.0298]],\n",
      "\n",
      "        [[-0.0239, -0.0352, -0.0344,  ..., -0.0368, -0.0370, -0.0298]]],\n",
      "       grad_fn=<ConvolutionBackward0>) 0 0\n",
      "tensor([[[0.0004, 0.0004, 0.0004,  ..., 0.0001, 0.0001, 0.0001]],\n",
      "\n",
      "        [[0.0003, 0.0003, 0.0003,  ..., 0.0001, 0.0001, 0.0001]],\n",
      "\n",
      "        [[0.0002, 0.0002, 0.0002,  ..., 0.0003, 0.0003, 0.0003]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0003, 0.0003, 0.0003,  ..., 0.0001, 0.0001, 0.0001]],\n",
      "\n",
      "        [[0.0002, 0.0002, 0.0002,  ..., 0.0001, 0.0001, 0.0001]],\n",
      "\n",
      "        [[0.0003, 0.0003, 0.0003,  ..., 0.0001, 0.0001, 0.0001]]]) tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "       grad_fn=<ConvolutionBackward0>) 0 1\n",
      "tensor([[[2.1065e-04, 2.1185e-04, 2.1306e-04,  ..., 8.9402e-05,\n",
      "          8.9307e-05, 8.9212e-05]],\n",
      "\n",
      "        [[5.1268e-04, 5.1474e-04, 5.1682e-04,  ..., 2.0397e-04,\n",
      "          2.0362e-04, 2.0328e-04]],\n",
      "\n",
      "        [[3.1431e-04, 3.1579e-04, 3.1729e-04,  ..., 4.5497e-05,\n",
      "          4.5448e-05, 4.5399e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.4323e-04, 2.4451e-04, 2.4580e-04,  ..., 4.1302e-05,\n",
      "          4.1252e-05, 4.1202e-05]],\n",
      "\n",
      "        [[2.2644e-04, 2.2769e-04, 2.2895e-04,  ..., 5.9146e-05,\n",
      "          5.9097e-05, 5.9049e-05]],\n",
      "\n",
      "        [[2.0539e-04, 2.0661e-04, 2.0785e-04,  ..., 1.5960e-04,\n",
      "          1.5924e-04, 1.5888e-04]]]) tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "       grad_fn=<ConvolutionBackward0>) 0 2\n",
      "Epoch 0 loss: nan\n",
      "tensor([[[3.3369e-04, 3.3510e-04, 3.3652e-04,  ..., 9.1159e-05,\n",
      "          9.1072e-05, 9.0986e-05]],\n",
      "\n",
      "        [[3.2401e-04, 3.2555e-04, 3.2712e-04,  ..., 2.1763e-04,\n",
      "          2.1720e-04, 2.1678e-04]],\n",
      "\n",
      "        [[2.1481e-04, 2.1602e-04, 2.1725e-04,  ..., 8.9395e-05,\n",
      "          8.9275e-05, 8.9155e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.0154e-04, 2.0275e-04, 2.0396e-04,  ..., 1.4172e-04,\n",
      "          1.4144e-04, 1.4116e-04]],\n",
      "\n",
      "        [[3.1431e-04, 3.1579e-04, 3.1729e-04,  ..., 4.5497e-05,\n",
      "          4.5448e-05, 4.5399e-05]],\n",
      "\n",
      "        [[4.8161e-04, 4.8365e-04, 4.8571e-04,  ..., 1.4423e-04,\n",
      "          1.4404e-04, 1.4385e-04]]]) tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "       grad_fn=<ConvolutionBackward0>) 1 0\n",
      "tensor([[[2.8386e-04, 2.8521e-04, 2.8657e-04,  ..., 1.8626e-04,\n",
      "          1.8595e-04, 1.8564e-04]],\n",
      "\n",
      "        [[2.2644e-04, 2.2769e-04, 2.2895e-04,  ..., 5.9146e-05,\n",
      "          5.9097e-05, 5.9049e-05]],\n",
      "\n",
      "        [[3.9294e-04, 3.9465e-04, 3.9637e-04,  ..., 9.4354e-05,\n",
      "          9.4254e-05, 9.4154e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.0728e-04, 3.0871e-04, 3.1015e-04,  ..., 6.7893e-05,\n",
      "          6.7821e-05, 6.7749e-05]],\n",
      "\n",
      "        [[2.7062e-04, 2.7196e-04, 2.7331e-04,  ..., 7.8373e-05,\n",
      "          7.8226e-05, 7.8079e-05]],\n",
      "\n",
      "        [[2.1065e-04, 2.1185e-04, 2.1306e-04,  ..., 8.9402e-05,\n",
      "          8.9307e-05, 8.9212e-05]]]) tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "       grad_fn=<ConvolutionBackward0>) 1 1\n",
      "tensor([[[2.2511e-04, 2.2631e-04, 2.2752e-04,  ..., 8.8702e-05,\n",
      "          8.8610e-05, 8.8518e-05]],\n",
      "\n",
      "        [[6.8608e-04, 6.8868e-04, 6.9131e-04,  ..., 1.6402e-04,\n",
      "          1.6377e-04, 1.6352e-04]],\n",
      "\n",
      "        [[4.8071e-04, 4.8292e-04, 4.8516e-04,  ..., 2.8591e-05,\n",
      "          2.8561e-05, 2.8530e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.9797e-04, 1.9913e-04, 2.0031e-04,  ..., 2.0166e-04,\n",
      "          2.0124e-04, 2.0083e-04]],\n",
      "\n",
      "        [[5.0821e-04, 5.1018e-04, 5.1216e-04,  ..., 2.0736e-04,\n",
      "          2.0703e-04, 2.0670e-04]],\n",
      "\n",
      "        [[2.5282e-04, 2.5412e-04, 2.5544e-04,  ..., 2.2130e-04,\n",
      "          2.2091e-04, 2.2052e-04]]]) tensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "       grad_fn=<ConvolutionBackward0>) 1 2\n"
     ]
    }
   ],
   "source": [
    "time_ = time.time() # Assigns time to variable time_\n",
    "\n",
    "train_loss_epoch = []\n",
    "valid_loss_epoch = []\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for index, (inputs, labels) in enumerate(train_dataloader):\n",
    "        #inputs = inputs.squeeze(1)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        print(inputs,outputs, e, index)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(1)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    train_loss_epoch.append(epoch_loss)\n",
    "    \n",
    "    model.eval() # Model to evaluation mode\n",
    "    valid_loss = 0.0\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    loss_list_test = []\n",
    "\n",
    "    # Loop for testing\n",
    "    for inputs, labels in valid_dataloader:\n",
    "        #Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        valid_loss += loss.item() * inputs.size(1)\n",
    "\n",
    "        _, labels = torch.min(labels, 1)\n",
    "        _, predicts = torch.min(outputs.data, 1)\n",
    "        predicts = predicts.unsqueeze(1)\n",
    "        valid_total += labels.size(0)\n",
    "        valid_correct += (predicts == labels).float().mean()\n",
    "        \n",
    "    epoch_loss = valid_loss / len(valid_dataloader.dataset)\n",
    "    valid_loss_epoch.append(epoch_loss)  \n",
    "           \n",
    "    \n",
    "    if(int(e) % 10) == 0:\n",
    "        print(f'Epoch {e} loss: {epoch_loss:.4f}')\n",
    "\n",
    "print(f'Time Elapsed: {round(time.time()-time_, 5)} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a934054-d70f-4746-9633-793ef8ff7631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# valid_loss_epoch = []\n",
    "\n",
    "# for e in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     loss_list_valid = []\n",
    "     \n",
    "#     model.eval() # Model to evaluation mode\n",
    "\n",
    "#     valid_loss = 0.0\n",
    "#     valid_correct = 0\n",
    "#     valid_total = 0\n",
    "#     loss_list_test = []\n",
    "\n",
    "#     # Loop for testing\n",
    "#     for inputs, labels in valid_dataloader:\n",
    "#         #Forward pass\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         valid_loss += loss.item() * inputs.size(1)\n",
    "\n",
    "#         _, labels = torch.min(labels, 1)\n",
    "#         _, predicts = torch.min(outputs.data, 1)\n",
    "#         predicts = predicts.unsqueeze(1)\n",
    "#         valid_total += labels.size(0)\n",
    "#         valid_correct += (predicts == labels).float().mean()\n",
    "        \n",
    "#     epoch_loss = valid_loss / len(valid_dataloader.dataset)\n",
    "#     valid_loss_epoch.append(epoch_loss)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908ab7b8-3331-4c33-8317-784aa259894a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.linspace(1, num_epochs, num_epochs)\n",
    "\n",
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "ax.plot(x, valid_loss_epoch, label='Validation Loss')\n",
    "ax.plot(x, train_loss_epoch, label='Training Loss' )\n",
    "\n",
    "matplotlib.pyplot.ylim([0.0, 0.001])\n",
    "matplotlib.pyplot.xlabel('Number of Epochs')\n",
    "matplotlib.pyplot.ylabel('Loss')\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c344731-cb9e-47f7-a9ea-fff4b258bef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluating Model Performance with Test Data\n",
    "\n",
    "model.eval() # Model to evaluation mode\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "loss_list_test = []\n",
    "\n",
    "# Loop for testing\n",
    "for inputs, labels in test_dataloader:\n",
    "    #Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    test_loss += loss.item() * inputs.size(1)\n",
    "    loss_list_test.append(loss)\n",
    "    \n",
    "    _, labels = torch.min(labels, 1)\n",
    "    _, predicts = torch.min(outputs.data, 1)\n",
    "    predicts = predicts.unsqueeze(1)\n",
    "    test_total += labels.size(0)\n",
    "    test_correct += (predicts == labels).float().mean()\n",
    "\n",
    "accuracy = (test_correct / test_total)*100\n",
    "test_loss /= len(test_dataloader.dataset)\n",
    "print(f' Mean Loss of Function: {test_loss}, Accuracy: {accuracy}')\n",
    "print(labels.shape, outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81757e-bcf7-4219-9277-19850d0edb55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_dataloader:\n",
    "        predictions = model(inputs)\n",
    "\n",
    "predictions_numpy = predictions.cpu().numpy().reshape(10,-1)\n",
    "pred = pd.DataFrame(predictions_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d91cd3-1e3b-4cfe-9083-3fdd77857096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_60 = pd.read_csv('/home/fostooq/NMR_Upscale_UW_DIRECT/spectral_data/400MHz/spectral_data_11_00022.csv')\n",
    "df_x = df_60['60MHz_intensity']\n",
    "df_x = df_x.to_numpy()\n",
    "df_x = torch.Tensor(df_x).unsqueeze(0).unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950abca-3ecc-475a-88a1-b0779dd1629b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model(df_x)\n",
    "predictions_numpy = predictions.detach().cpu().numpy()\n",
    "predictions_numpy=predictions_numpy.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a7efc0-fdcb-4537-baf5-64498cb3f09c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nmrsim.plt.mplplot_lineshape(df_60['60MHz_ppm'], df_60['60MHz_intensity'], limits=(-0.5, 10.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60162ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_numpy.shape\n",
    "\n",
    "\n",
    "np.square(predictions_numpy - df_60['60MHz_intensity']).mean(), np.square(predictions_numpy - df_60['400MHz_intensity']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4a778-ca99-40c3-8788-399b1deb9e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "x = np.linspace(-.5,10.5,5500)\n",
    "y = predictions_numpy\n",
    "\n",
    "\n",
    "nmrsim.plt.mplplot_lineshape(x, y, limits=(-0.5, 10.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826cff8-48f8-4218-a324-d74e53839e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nmrsim.plt.mplplot_lineshape(np.array(df_60['400MHz_ppm']), np.array(df_60['400MHz_intensity']), limits=(-0.5, 10.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb0953-0686-41e8-872c-9672a6de63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = glob.glob(os.path.join('/home/fostooq/NMR_Upscale_UW_DIRECT/spectral_data/400MHz/spectral_data_*.csv'))\n",
    "\n",
    "y_60 = []\n",
    "y_400 = []\n",
    "\n",
    "for file in test:\n",
    "    df = pd.read_csv(file)\n",
    "    array_60 = df['60MHz_intensity'].to_numpy()\n",
    "    array_400 = df['400MHz_intensity'].to_numpy()\n",
    "    y_60.append(array_60)\n",
    "    y_400.append(array_400)\n",
    "\n",
    "tensor = torch.Tensor(y_400)\n",
    "reshaped_tensor = tensor.unsqueeze(1)\n",
    "reshaped_tensor_2 = reshaped_tensor.squeeze(1)\n",
    "\n",
    "print(reshaped_tensor.shape)\n",
    "print(reshaped_tensor_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072c108-a76a-4a4b-b2c6-b4c6fa48e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training loop for optuna:\n",
    "def objective(trial):\n",
    "    # Generate the model\n",
    "    model = LinearVAE(trial).to(device)\n",
    "    # Generate optimizers\n",
    "    # Try Adam, AdaDelta, Adagrad, RMSprop, SGD\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'Adadelta', 'Adagrad', 'RMSprop', 'SGD'])\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    batch_size_trial = trial.suggest_int('batch_size', 64, 256, step=64)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 5, 50, step=5)\n",
    "    criterion = nn.MSELoss()\n",
    "    # Load Data\n",
    "    # Establishing and loading data into notebook\n",
    "    dataset = GHzData()\n",
    "    #Splitting the data\n",
    "    train_X, test_X, train_y, test_y = train_test_split(dataset.tensor_60, dataset.tensor_400,\n",
    "                                                        test_size=0.1)\n",
    "    # Splits train data into validation data\n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y,\n",
    "                                                          test_size=0.1)\n",
    "    # Creating datasets\n",
    "    train_dataset = TensorDataset(train_X, train_y)\n",
    "    test_dataset = TensorDataset(test_X, test_y)\n",
    "    valid_dataset = TensorDataset(valid_X, valid_y)\n",
    "    # Batch size change to higher batch sizes\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size_trial, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size_trial, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_trial, shuffle=True)\n",
    "    # Paste training loop here\n",
    "    for epoch in range(num_epochs):\n",
    "        train_epoch_loss = fit(model, train_dataloader, optimizer, criterion)\n",
    "        val_epoch_loss = validate(model, valid_dataloader, optimizer, criterion)\n",
    "    trial.report(train_epoch_loss, epoch)\n",
    "    # Handle pruning\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    return train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398fd9b-709c-4b82-b2ac-a946eeec4986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff8df6-ef01-4c8a-bc54-937398642f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
